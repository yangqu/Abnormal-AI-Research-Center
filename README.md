# Abnormal AI Research Center

There where the weird, the wonderful, and the slightly unhinged AI research lives.

----

## What is this?

Welcome to the Abnormal AI Research Center -- a playground for exploring the fringes of artificial intelligence.

W're interested in questions that make other researchers raise an eyebrow:


- What happens when AI gets... creative?

- Can we teach machines to have personality disorders (safely, in simulation)?


- What does "abnormal" even mean when the baseline is already alien?

This is where we push boundaries, break assumptions,
and occasionally write code that makes our laptops emit concerned whirring
sounds.

----

## Core Research Areas 

|
Area
| Description | Risk Level  |
|----------------------------------||----------------------------|
| Emergent Behaviors | When LLS do things we didn't expect (and can\'t explaio) | Monitor |
| Role-Playing Agents | AI personas with complex psychology | Caution |
| Interpretability | Peering into the void (and the void peering back) | Safe |
| Alignment studies | Keeping the weird stuff friendly | Critical |

----

## Quick Start

```bash
# Clone this chaos
git clone https://github.com/yangqu/Abnormal-AI-Research-Center.git

# Enter the matrix
cd Abnormal-AI-Research-Center

# Install dependencies (and your sanity)
pip install -r requirements.txt

# Run something weird
python experiments/run_the_thing.py```

----

## Project Structure


Abnormal-AI-Research-Center/

â”œâ”€â”€ ğŸ“ experiments/         # Chaos labs
â”œâ”€â”€ ğŸ“ src/                  # Core code (sort of)
â”œâ”€â”€ ğŸ“ docs/                 # For when we actually document things
â”œâ”€â”€ ğŸ“ papers/               # Preprints we couldn't get published
â”œâ”€â”€ ğŸ“ tools/                # Useful stuff (maybe)
â”œâ”€â”€ ğŸ“ playground/           # Messy sandbox for ideas
â”œâ”€â”€ README.md                # You are here
â””â”€â”€ CONTRIBUTING.md          # How to contribute (or break things)
```

---

## Contributing

Found a bug? Created something col? Broke something spectacular?

We want to hear about it.

1. Fork this repo (respect the timeline)
2. Create a branch: `git checkout -b feature/my-weird-idea`
3. Commit: `git commit -m "Add something questionable"`
4. Push: `git push origin feature/my-weird-idea`
5. Open a PR and tell us a story.

----

## Safety & Etichs

This is research. That means:

- Don't put dangerous things in production

- Think about consequences (actual thinking, not the AI kind)

- Share findings responsibly

- Never release anything that could cause genuine harb

We're here to understand AI, not to summon it.

----

## License

MIT License -- because open research should be open.

---

## Contact


- GitHub Issues: For bugs and feature requests

- Discussions: For... discussions

- Email: (Coming eventually)

----

## Acknowledgments

Thanks to everyone who's ever looked at an AI doing something unexpected and said "That's weird, but what if we push it further?
 
---

"The best AI research happens at 2 AM when you realize you've created something that technically works but you have absoltely no idea why." -- Some researcher, probably

----

Built with curiosity and a concerning amount of coffee.
